<<<<<<< HEAD
{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"segm_w_on_the_fly_augm.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"KslpdmUtsrRq"},"source":["# Semantic Segmentation with on the fly Data Augmentation\n"]},{"cell_type":"markdown","metadata":{"id":"view-in-github"},"source":["<a href=\"https://colab.research.google.com/github/gerasimos-matidis/my_icdar/blob/main/segm_w_on_the_fly_augm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"code","metadata":{"id":"O0XXCeIchGU0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638454639702,"user_tz":-60,"elapsed":205,"user":{"displayName":"Mager","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15875237439058818003"}},"outputId":"e97a5edd-fce9-4a43-dc72-6cfb21b3a514"},"source":["# Mount google drive and move to the project directory\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","%cd gdrive/MyDrive/my_icdar"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","[Errno 2] No such file or directory: 'gdrive/MyDrive/my_icdar'\n","/content/gdrive/MyDrive/my_icdar\n"]}]},{"cell_type":"code","metadata":{"id":"0m3L9i6n-cCC"},"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","from keras_preprocessing.image import ImageDataGenerator\n","from gm_networks import unet_model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4D3hgHsHvHrt"},"source":["# Load the initial input and output images and expand their dimensions to fit the ImageDataGenerator \n","# For inputs: initial_dimensions = (width, height, 3) ---> new_dimensions = (1, width, height, 3)\n","# For outputs: initial_dimensions = (width, height) ---> new_dimensions = (1, width, height, 1)\n","\n","x_initial_train = plt.imread('train/101-INPUT.jpg')\n","y_initial_train = plt.imread('train/101-OUTPUT-GT.png')\n","x_initial_train = np.expand_dims(x_initial_train, 0) \n","y_initial_train = np.expand_dims(y_initial_train, (0, -1)) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b62OZ7Rx9Un7"},"source":["# Define the new size to create images of size (NEW_SIZE, NEW_SIZE), as well as define the number of train and validation images to be created\n","NEW_SIZE = 512\n","TRAIN_IMAGES_NUMBER = 300"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CWcEEEXG5d8K"},"source":["# Concatenate the respective inputs and outputs to ensure that they will undergo the same crop\n","concatenated_images_train = np.concatenate([x_initial_train, y_initial_train], -1)\n","\n","# Initialize the tensors for the training batches\n","croped_images_train = np.zeros([TRAIN_IMAGES_NUMBER, NEW_SIZE, NEW_SIZE, 4])\n","\n","# Random croping\n","for i in range(TRAIN_IMAGES_NUMBER):\n","    \n","    t = tf.image.random_crop(concatenated_images_train, size=[1, NEW_SIZE, NEW_SIZE, 4])\n","    croped_images_train[i] = t[0]\n","\n","# Separate the inputs from the outputs to create the final batches\n","x_train = croped_images_train[:, :, :, :3]\n","y_train = np.expand_dims(croped_images_train[:, :, :, 3], -1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uD8KTAOSDZXE"},"source":["# Create dictionaries with the alterations to be used for the data augmentation operations for inputs and outputs\n","\"\"\"\"\n","NOTE: It is important to use exact the same values for both dictionaries (for inputs and outputs). \n","The reason why we create 2 dictionaries instead of a common one is because  we want to add the \n","preprocessing function for the output masks (This function sets all the pixel values of the mask to 0 or 1. \n","While the initial images are binary, after the data augmentation operations, such as rotations and shifts, \n","pixels with intermediate values are created due to interpolation)\n","\"\"\"\n","x_datagen_args = dict(\n","    rotation_range=25, \n","    width_shift_range=0.1, \n","    height_shift_range=0.1,\n","    shear_range=0.1,\n","    zoom_range=0.1,\n","    horizontal_flip=True,\n","    vertical_flip=True,\n","    fill_mode='reflect')\n","\n","y_datagen_args = dict(\n","    rotation_range=25, \n","    width_shift_range=0.1, \n","    height_shift_range=0.1,\n","    shear_range=0.1,\n","    zoom_range=0.1,\n","    horizontal_flip=True,\n","    vertical_flip=True,\n","    fill_mode='reflect', \n","    preprocessing_function = lambda x: np.where(x>0, 1, 0).astype(x.dtype))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"t9mScpdzDhK2"},"source":["BATCH_SIZE = 8\n","\n","# Instatiate the generators\n","x_datagen = ImageDataGenerator(**x_datagen_args)\n","y_datagen = ImageDataGenerator(**y_datagen_args)\n","\n","# Setting the same seed number for both generators leads to the same random alterations for both generators\n","seed = 18\n","x_datagen.fit(x_train, augment=True, seed=seed)\n","y_datagen.fit(y_train, augment=True, seed=seed)\n","\n","x_generator_train = x_datagen.flow(x_train, seed=seed, batch_size=BATCH_SIZE)\n","y_generator_train = y_datagen.flow(y_train, seed=seed, batch_size=BATCH_SIZE)\n","\n","train_generator = zip(x_generator_train, y_generator_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8fF9xLlD7KM4"},"source":["INITIAL_FILTERS = 32\n","EPOCHS = 100\n","STEPS_PER_EPOCH = TRAIN_IMAGES_NUMBER // BATCH_SIZE"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"wwG7zHnrDka3","executionInfo":{"status":"error","timestamp":1638455193746,"user_tz":-60,"elapsed":199373,"user":{"displayName":"Mager","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15875237439058818003"}},"outputId":"66694cca-bf8a-4e2e-d226-498d7bf06baa"},"source":["# Define the model and train\n","model = unet_model(input_shape=(NEW_SIZE, NEW_SIZE, 3), initial_filters=INITIAL_FILTERS)\n","model.summary()\n","model.compile(optimizer='adam',\n","              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","              metrics=['accuracy'])\n","\n","history = model.fit_generator(train_generator, steps_per_epoch=STEPS_PER_EPOCH, epochs=EPOCHS)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_3\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_4 (InputLayer)           [(None, 512, 512, 3  0           []                               \n","                                )]                                                                \n","                                                                                                  \n"," conv2d_57 (Conv2D)             (None, 512, 512, 32  896         ['input_4[0][0]']                \n","                                )                                                                 \n","                                                                                                  \n"," batch_normalization_54 (BatchN  (None, 512, 512, 32  128        ['conv2d_57[0][0]']              \n"," ormalization)                  )                                                                 \n","                                                                                                  \n"," activation_54 (Activation)     (None, 512, 512, 32  0           ['batch_normalization_54[0][0]'] \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_58 (Conv2D)             (None, 512, 512, 32  9248        ['activation_54[0][0]']          \n","                                )                                                                 \n","                                                                                                  \n"," batch_normalization_55 (BatchN  (None, 512, 512, 32  128        ['conv2d_58[0][0]']              \n"," ormalization)                  )                                                                 \n","                                                                                                  \n"," activation_55 (Activation)     (None, 512, 512, 32  0           ['batch_normalization_55[0][0]'] \n","                                )                                                                 \n","                                                                                                  \n"," max_pooling2d_12 (MaxPooling2D  (None, 256, 256, 32  0          ['activation_55[0][0]']          \n"," )                              )                                                                 \n","                                                                                                  \n"," conv2d_59 (Conv2D)             (None, 256, 256, 64  18496       ['max_pooling2d_12[0][0]']       \n","                                )                                                                 \n","                                                                                                  \n"," batch_normalization_56 (BatchN  (None, 256, 256, 64  256        ['conv2d_59[0][0]']              \n"," ormalization)                  )                                                                 \n","                                                                                                  \n"," activation_56 (Activation)     (None, 256, 256, 64  0           ['batch_normalization_56[0][0]'] \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_60 (Conv2D)             (None, 256, 256, 64  36928       ['activation_56[0][0]']          \n","                                )                                                                 \n","                                                                                                  \n"," batch_normalization_57 (BatchN  (None, 256, 256, 64  256        ['conv2d_60[0][0]']              \n"," ormalization)                  )                                                                 \n","                                                                                                  \n"," activation_57 (Activation)     (None, 256, 256, 64  0           ['batch_normalization_57[0][0]'] \n","                                )                                                                 \n","                                                                                                  \n"," max_pooling2d_13 (MaxPooling2D  (None, 128, 128, 64  0          ['activation_57[0][0]']          \n"," )                              )                                                                 \n","                                                                                                  \n"," conv2d_61 (Conv2D)             (None, 128, 128, 12  73856       ['max_pooling2d_13[0][0]']       \n","                                8)                                                                \n","                                                                                                  \n"," batch_normalization_58 (BatchN  (None, 128, 128, 12  512        ['conv2d_61[0][0]']              \n"," ormalization)                  8)                                                                \n","                                                                                                  \n"," activation_58 (Activation)     (None, 128, 128, 12  0           ['batch_normalization_58[0][0]'] \n","                                8)                                                                \n","                                                                                                  \n"," conv2d_62 (Conv2D)             (None, 128, 128, 12  147584      ['activation_58[0][0]']          \n","                                8)                                                                \n","                                                                                                  \n"," batch_normalization_59 (BatchN  (None, 128, 128, 12  512        ['conv2d_62[0][0]']              \n"," ormalization)                  8)                                                                \n","                                                                                                  \n"," activation_59 (Activation)     (None, 128, 128, 12  0           ['batch_normalization_59[0][0]'] \n","                                8)                                                                \n","                                                                                                  \n"," dropout_9 (Dropout)            (None, 128, 128, 12  0           ['activation_59[0][0]']          \n","                                8)                                                                \n","                                                                                                  \n"," max_pooling2d_14 (MaxPooling2D  (None, 64, 64, 128)  0          ['dropout_9[0][0]']              \n"," )                                                                                                \n","                                                                                                  \n"," conv2d_63 (Conv2D)             (None, 64, 64, 256)  295168      ['max_pooling2d_14[0][0]']       \n","                                                                                                  \n"," batch_normalization_60 (BatchN  (None, 64, 64, 256)  1024       ['conv2d_63[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_60 (Activation)     (None, 64, 64, 256)  0           ['batch_normalization_60[0][0]'] \n","                                                                                                  \n"," conv2d_64 (Conv2D)             (None, 64, 64, 256)  590080      ['activation_60[0][0]']          \n","                                                                                                  \n"," batch_normalization_61 (BatchN  (None, 64, 64, 256)  1024       ['conv2d_64[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_61 (Activation)     (None, 64, 64, 256)  0           ['batch_normalization_61[0][0]'] \n","                                                                                                  \n"," dropout_10 (Dropout)           (None, 64, 64, 256)  0           ['activation_61[0][0]']          \n","                                                                                                  \n"," max_pooling2d_15 (MaxPooling2D  (None, 32, 32, 256)  0          ['dropout_10[0][0]']             \n"," )                                                                                                \n","                                                                                                  \n"," conv2d_65 (Conv2D)             (None, 32, 32, 512)  1180160     ['max_pooling2d_15[0][0]']       \n","                                                                                                  \n"," batch_normalization_62 (BatchN  (None, 32, 32, 512)  2048       ['conv2d_65[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_62 (Activation)     (None, 32, 32, 512)  0           ['batch_normalization_62[0][0]'] \n","                                                                                                  \n"," conv2d_66 (Conv2D)             (None, 32, 32, 512)  2359808     ['activation_62[0][0]']          \n","                                                                                                  \n"," batch_normalization_63 (BatchN  (None, 32, 32, 512)  2048       ['conv2d_66[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_63 (Activation)     (None, 32, 32, 512)  0           ['batch_normalization_63[0][0]'] \n","                                                                                                  \n"," dropout_11 (Dropout)           (None, 32, 32, 512)  0           ['activation_63[0][0]']          \n","                                                                                                  \n"," conv2d_transpose_12 (Conv2DTra  (None, 64, 64, 256)  1179904    ['dropout_11[0][0]']             \n"," nspose)                                                                                          \n","                                                                                                  \n"," concatenate_12 (Concatenate)   (None, 64, 64, 512)  0           ['conv2d_transpose_12[0][0]',    \n","                                                                  'dropout_10[0][0]']             \n","                                                                                                  \n"," conv2d_67 (Conv2D)             (None, 64, 64, 256)  1179904     ['concatenate_12[0][0]']         \n","                                                                                                  \n"," batch_normalization_64 (BatchN  (None, 64, 64, 256)  1024       ['conv2d_67[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_64 (Activation)     (None, 64, 64, 256)  0           ['batch_normalization_64[0][0]'] \n","                                                                                                  \n"," conv2d_68 (Conv2D)             (None, 64, 64, 256)  590080      ['activation_64[0][0]']          \n","                                                                                                  \n"," batch_normalization_65 (BatchN  (None, 64, 64, 256)  1024       ['conv2d_68[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_65 (Activation)     (None, 64, 64, 256)  0           ['batch_normalization_65[0][0]'] \n","                                                                                                  \n"," conv2d_transpose_13 (Conv2DTra  (None, 128, 128, 12  295040     ['activation_65[0][0]']          \n"," nspose)                        8)                                                                \n","                                                                                                  \n"," concatenate_13 (Concatenate)   (None, 128, 128, 25  0           ['conv2d_transpose_13[0][0]',    \n","                                6)                                'dropout_9[0][0]']              \n","                                                                                                  \n"," conv2d_69 (Conv2D)             (None, 128, 128, 12  295040      ['concatenate_13[0][0]']         \n","                                8)                                                                \n","                                                                                                  \n"," batch_normalization_66 (BatchN  (None, 128, 128, 12  512        ['conv2d_69[0][0]']              \n"," ormalization)                  8)                                                                \n","                                                                                                  \n"," activation_66 (Activation)     (None, 128, 128, 12  0           ['batch_normalization_66[0][0]'] \n","                                8)                                                                \n","                                                                                                  \n"," conv2d_70 (Conv2D)             (None, 128, 128, 12  147584      ['activation_66[0][0]']          \n","                                8)                                                                \n","                                                                                                  \n"," batch_normalization_67 (BatchN  (None, 128, 128, 12  512        ['conv2d_70[0][0]']              \n"," ormalization)                  8)                                                                \n","                                                                                                  \n"," activation_67 (Activation)     (None, 128, 128, 12  0           ['batch_normalization_67[0][0]'] \n","                                8)                                                                \n","                                                                                                  \n"," conv2d_transpose_14 (Conv2DTra  (None, 256, 256, 64  73792      ['activation_67[0][0]']          \n"," nspose)                        )                                                                 \n","                                                                                                  \n"," concatenate_14 (Concatenate)   (None, 256, 256, 12  0           ['conv2d_transpose_14[0][0]',    \n","                                8)                                'activation_57[0][0]']          \n","                                                                                                  \n"," conv2d_71 (Conv2D)             (None, 256, 256, 64  73792       ['concatenate_14[0][0]']         \n","                                )                                                                 \n","                                                                                                  \n"," batch_normalization_68 (BatchN  (None, 256, 256, 64  256        ['conv2d_71[0][0]']              \n"," ormalization)                  )                                                                 \n","                                                                                                  \n"," activation_68 (Activation)     (None, 256, 256, 64  0           ['batch_normalization_68[0][0]'] \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_72 (Conv2D)             (None, 256, 256, 64  36928       ['activation_68[0][0]']          \n","                                )                                                                 \n","                                                                                                  \n"," batch_normalization_69 (BatchN  (None, 256, 256, 64  256        ['conv2d_72[0][0]']              \n"," ormalization)                  )                                                                 \n","                                                                                                  \n"," activation_69 (Activation)     (None, 256, 256, 64  0           ['batch_normalization_69[0][0]'] \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_transpose_15 (Conv2DTra  (None, 512, 512, 32  18464      ['activation_69[0][0]']          \n"," nspose)                        )                                                                 \n","                                                                                                  \n"," concatenate_15 (Concatenate)   (None, 512, 512, 64  0           ['conv2d_transpose_15[0][0]',    \n","                                )                                 'activation_55[0][0]']          \n","                                                                                                  \n"," conv2d_73 (Conv2D)             (None, 512, 512, 32  18464       ['concatenate_15[0][0]']         \n","                                )                                                                 \n","                                                                                                  \n"," batch_normalization_70 (BatchN  (None, 512, 512, 32  128        ['conv2d_73[0][0]']              \n"," ormalization)                  )                                                                 \n","                                                                                                  \n"," activation_70 (Activation)     (None, 512, 512, 32  0           ['batch_normalization_70[0][0]'] \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_74 (Conv2D)             (None, 512, 512, 32  9248        ['activation_70[0][0]']          \n","                                )                                                                 \n","                                                                                                  \n"," batch_normalization_71 (BatchN  (None, 512, 512, 32  128        ['conv2d_74[0][0]']              \n"," ormalization)                  )                                                                 \n","                                                                                                  \n"," activation_71 (Activation)     (None, 512, 512, 32  0           ['batch_normalization_71[0][0]'] \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_75 (Conv2D)             (None, 512, 512, 1)  33          ['activation_71[0][0]']          \n","                                                                                                  \n","==================================================================================================\n","Total params: 8,642,273\n","Trainable params: 8,636,385\n","Non-trainable params: 5,888\n","__________________________________________________________________________________________________\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  \n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","37/37 [==============================] - 122s 2s/step - loss: nan - accuracy: 0.4050\n","Epoch 2/100\n","37/37 [==============================] - 68s 2s/step - loss: nan - accuracy: 0.4147\n","Epoch 3/100\n"," 4/37 [==>...........................] - ETA: 47s - loss: nan - accuracy: 0.3779"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-21-2650f90e13d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m               metrics=['accuracy'])\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSTEPS_PER_EPOCH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2028\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2029\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2030\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   2031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2032\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mdoc_controls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_not_generate_docs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1219\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1220\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1221\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1222\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    434\u001b[0m     \"\"\"\n\u001b[1;32m    435\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    293\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m       raise ValueError(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    314\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m       \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1032\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1033\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1102\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1103\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1104\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1105\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    552\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    548\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1147\u001b[0m     \"\"\"\n\u001b[1;32m   1148\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1113\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1115\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1116\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1117\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"AqagtySHcLPg"},"source":["# save the model and history of the training (loss, accuracy)\n","model_path = f'models/Unet_fitgen_inputsize{NEW_SIZE}_initialfilters{INITIAL_FILTERS}_epochs{EPOCHS}_stepsperepoch{STEPS_PER_EPOCH}'\n","model.save(model_path)\n","history_path = f'models/Unet_fitgen_inputsize{NEW_SIZE}_initialfilters{INITIAL_FILTERS}_epochs{EPOCHS}_stepsperepoch{STEPS_PER_EPOCH}_history'\n","np.save('models/', history.history)"],"execution_count":null,"outputs":[]}]}
=======
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "segm_w_on_the_fly_augm.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gerasimos-matidis/my_icdar/blob/main/segm_w_on_the_fly_augm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KslpdmUtsrRq"
      },
      "source": [
        "# Semantic Segmentation with on the fly Data Augmentation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gerasimos-matidis/my_icdar/blob/main/segm_w_on_the_fly_augm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0XXCeIchGU0"
      },
      "source": [
        "# Mount google drive and move to the project directory\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "%cd gdrive/MyDrive/my_icdar"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0m3L9i6n-cCC"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras_preprocessing.image import ImageDataGenerator\n",
        "from gm_networks import unet_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4D3hgHsHvHrt"
      },
      "source": [
        "# Load the initial input and output images and expand their dimensions to fit the ImageDataGenerator \n",
        "# For inputs: initial_dimensions = (width, height, 3) ---> new_dimensions = (1, width, height, 3)\n",
        "# For outputs: initial_dimensions = (width, height) ---> new_dimensions = (1, width, height, 1)\n",
        "\n",
        "x_initial_train = plt.imread('train/101-INPUT.jpg')\n",
        "y_initial_train = plt.imread('train/101-OUTPUT-GT.png')\n",
        "x_initial_train = np.expand_dims(x_initial_train, 0) \n",
        "y_initial_train = np.expand_dims(y_initial_train, (0, -1)) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b62OZ7Rx9Un7"
      },
      "source": [
        "# Define the new size to create images of size (NEW_SIZE, NEW_SIZE), as well as define the number of train and validation images to be created\n",
        "NEW_SIZE = 512\n",
        "TRAIN_IMAGES_NUMBER = 300"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWcEEEXG5d8K"
      },
      "source": [
        "# Concatenate the respective inputs and outputs to ensure that they will undergo the same crop\n",
        "concatenated_images_train = np.concatenate([x_initial_train, y_initial_train], -1)\n",
        "\n",
        "# Initialize the tensors for the training batches\n",
        "croped_images_train = np.zeros([TRAIN_IMAGES_NUMBER, NEW_SIZE, NEW_SIZE, 4])\n",
        "\n",
        "# Random croping\n",
        "for i in range(TRAIN_IMAGES_NUMBER):\n",
        "    \n",
        "    t = tf.image.random_crop(concatenated_images_train, size=[1, NEW_SIZE, NEW_SIZE, 4])\n",
        "    croped_images_train[i] = t[0]\n",
        "\n",
        "# Separate the inputs from the outputs to create the final batches\n",
        "x_train = croped_images_train[:, :, :, :3]\n",
        "y_train = np.expand_dims(croped_images_train[:, :, :, 3], -1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uD8KTAOSDZXE"
      },
      "source": [
        "# Create dictionaries with the alterations to be used for the data augmentation operations for inputs and outputs\n",
        "\"\"\"\"\n",
        "NOTE: It is important to use exact the same values for both dictionaries (for inputs and outputs). \n",
        "The reason why we create 2 dictionaries instead of a common one is because  we want to add the \n",
        "preprocessing function for the output masks (This function sets all the pixel values of the mask to 0 or 1. \n",
        "While the initial images are binary, after the data augmentation operations, such as rotations and shifts, \n",
        "pixels with intermediate values are created due to interpolation)\n",
        "\"\"\"\n",
        "x_datagen_args = dict(\n",
        "    rotation_range=25, \n",
        "    width_shift_range=0.1, \n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    fill_mode='reflect')\n",
        "\n",
        "y_datagen_args = dict(\n",
        "    rotation_range=25, \n",
        "    width_shift_range=0.1, \n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    fill_mode='reflect', \n",
        "    preprocessing_function = lambda x: np.where(x>0, 1, 0).astype(x.dtype))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9mScpdzDhK2"
      },
      "source": [
        "BATCH_SIZE = 8\n",
        "\n",
        "# Instatiate the generators\n",
        "x_datagen = ImageDataGenerator(**x_datagen_args)\n",
        "y_datagen = ImageDataGenerator(**y_datagen_args)\n",
        "\n",
        "# Setting the same seed number for both generators leads to the same random alterations for both generators\n",
        "seed = 18\n",
        "x_datagen.fit(x_train, augment=True, seed=seed)\n",
        "y_datagen.fit(y_train, augment=True, seed=seed)\n",
        "\n",
        "x_generator_train = x_datagen.flow(x_train, seed=seed, batch_size=BATCH_SIZE)\n",
        "y_generator_train = y_datagen.flow(y_train, seed=seed, batch_size=BATCH_SIZE)\n",
        "\n",
        "train_generator = zip(x_generator_train, y_generator_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fF9xLlD7KM4"
      },
      "source": [
        "INITIAL_FILTERS = 32\n",
        "EPOCHS = 100\n",
        "STEPS_PER_EPOCH = TRAIN_IMAGES_NUMBER // BATCH_SIZE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwG7zHnrDka3"
      },
      "source": [
        "# Define the model and train\n",
        "model = unet_model(input_shape=(NEW_SIZE, NEW_SIZE, 3), initial_filters=INITIAL_FILTERS)\n",
        "model.summary()\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit_generator(train_generator, steps_per_epoch=STEPS_PER_EPOCH, epochs=EPOCHS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqagtySHcLPg"
      },
      "source": [
        "# save the model and history of the training (loss, accuracy)\n",
        "model_path = f'models/Unet_fitgen_inputsize{NEW_SIZE}_initialfilters{INITIAL_FILTERS}_epochs{EPOCHS}_stepsperepoch{STEPS_PER_EPOCH}'\n",
        "model.save(model_path)\n",
        "history_path = f'models/Unet_fitgen_inputsize{NEW_SIZE}_initialfilters{INITIAL_FILTERS}_epochs{EPOCHS}_stepsperepoch{STEPS_PER_EPOCH}_history'\n",
        "np.save('models/', history.history)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
>>>>>>> 72a8c39a132b16d662b42a29b75eaafd874b5570
