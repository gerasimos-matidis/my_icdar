{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KslpdmUtsrRq"
   },
   "source": [
    "# Semantic Segmentation with on-the-fly Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0m3L9i6n-cCC"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "from gm_networks import unet_model\n",
    "from utils import center_crop, normalize_data, create_dataset_from_one_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4D3hgHsHvHrt"
   },
   "outputs": [],
   "source": [
    "# Load the initial input/output images. Normalize the input images to [0, 1] \n",
    "x_initial_train = normalize_data(plt.imread('train/101-INPUT.jpg'))\n",
    "y_initial_train = plt.imread('train/101-OUTPUT-GT.png')\n",
    "x_initial_train = center_crop(x_initial_train, (2560, 2560))\n",
    "y_initial_train = center_crop(y_initial_train, (2560, 2560))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b62OZ7Rx9Un7"
   },
   "outputs": [],
   "source": [
    "# Model/training hyperparameters\n",
    "INPUT_SHAPE = (256, 256, 3)\n",
    "INITIAL_FILTERS = 32\n",
    "BATCH_SIZE = 1\n",
    "EPOCHS = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hMDjyp6H8GG1"
   },
   "outputs": [],
   "source": [
    "model = unet_model(input_shape=INPUT_SHAPE, initial_filters=INITIAL_FILTERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataset with independent patches\n",
    "MODE = 'independent_patches'\n",
    "x_train, y_train = create_dataset_from_one_image(x_initial_train, y_initial_train, INPUT_SHAPE[0], mode=MODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataset with overlapped patches\n",
    "MODE = 'overlapped_patches'\n",
    "x_train, y_train = create_dataset_from_one_image(x_initial_train, y_initial_train, INPUT_SHAPE[0], mode=MODE, patches_step=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataset with random patches\n",
    "MODE = 'random_patches'\n",
    "x_train, y_train = create_dataset_from_one_image(x_initial_train, y_initial_train, INPUT_SHAPE[0], mode=MODE, new_images_number=81)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "uD8KTAOSDZXE"
   },
   "outputs": [],
   "source": [
    "# Create dictionaries with the alterations to be used for the data augmentation operations for inputs and outputs\n",
    "\"\"\"\"\n",
    "NOTE: It is important to use exact the same values for the parameters in both dictionaries. \n",
    "The reason why we create 2 dictionaries instead of a common one is because  we want to add the \n",
    "preprocessing function for the output masks (this function sets all the pixel values of the mask to 0 or 1. \n",
    "While the initial ground truth images are binary, after the data augmentation operations, such as rotations and \n",
    "shifts, pixels with intermediate values are appeared due to interpolation)\n",
    "\"\"\"\n",
    "x_datagen_args = dict(\n",
    "    rotation_range=25, \n",
    "    width_shift_range=0.1, \n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    fill_mode='reflect') \n",
    "\n",
    "# TODO: Post a question in StackOverflow to check why nan values are created, when I use the 'normalize_data' \n",
    "# function (from utils.py) as a preprocessing_function in x_datagen_args\n",
    "\n",
    "y_datagen_args = x_datagen_args.copy()\n",
    "y_datagen_args['preprocessing_function'] = lambda x: np.where(x>0, 1, 0).astype(x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "t9mScpdzDhK2"
   },
   "outputs": [],
   "source": [
    "# Instatiate the generators\n",
    "x_datagen = ImageDataGenerator(**x_datagen_args)\n",
    "y_datagen = ImageDataGenerator(**y_datagen_args)\n",
    "\n",
    "# Setting the same seed number for both generators leads to the same random alterations for both generators\n",
    "seed = 19\n",
    "x_datagen.fit(x_train, augment=True, seed=seed)\n",
    "y_datagen.fit(y_train, augment=True, seed=seed)\n",
    "\n",
    "x_generator_train = x_datagen.flow(x_train, seed=seed, batch_size=BATCH_SIZE)\n",
    "y_generator_train = y_datagen.flow(y_train, seed=seed, batch_size=BATCH_SIZE)\n",
    "\n",
    "train_generator = zip(x_generator_train, y_generator_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "wwG7zHnrDka3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-24 01:17:50.479842: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 4s 10ms/step - loss: 0.7411 - accuracy: 0.5241\n",
      "Epoch 2/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.7007 - accuracy: 0.5643\n",
      "Epoch 3/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.6859 - accuracy: 0.5847\n",
      "Epoch 4/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.6759 - accuracy: 0.5989\n",
      "Epoch 5/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.6718 - accuracy: 0.6039\n",
      "Epoch 6/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.6661 - accuracy: 0.6104\n",
      "Epoch 7/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.6630 - accuracy: 0.6119\n",
      "Epoch 8/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.6578 - accuracy: 0.6180\n",
      "Epoch 9/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.6559 - accuracy: 0.6253\n",
      "Epoch 10/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.6509 - accuracy: 0.6271\n",
      "Epoch 11/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.6485 - accuracy: 0.6277\n",
      "Epoch 12/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.6477 - accuracy: 0.6267\n",
      "Epoch 13/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.6472 - accuracy: 0.6322\n",
      "Epoch 14/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.6433 - accuracy: 0.6349\n",
      "Epoch 15/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.6384 - accuracy: 0.6372\n",
      "Epoch 16/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.6387 - accuracy: 0.6369\n",
      "Epoch 17/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.6353 - accuracy: 0.6425\n",
      "Epoch 18/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.6310 - accuracy: 0.6475\n",
      "Epoch 19/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.6295 - accuracy: 0.6441\n",
      "Epoch 20/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.6266 - accuracy: 0.6519\n",
      "Epoch 21/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.6260 - accuracy: 0.6511\n",
      "Epoch 22/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.6201 - accuracy: 0.6585\n",
      "Epoch 23/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.6202 - accuracy: 0.6577\n",
      "Epoch 24/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.6135 - accuracy: 0.6626\n",
      "Epoch 25/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.6116 - accuracy: 0.6655\n",
      "Epoch 26/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.6057 - accuracy: 0.6709\n",
      "Epoch 27/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.6072 - accuracy: 0.6703\n",
      "Epoch 28/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.5987 - accuracy: 0.6792\n",
      "Epoch 29/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.5906 - accuracy: 0.6837\n",
      "Epoch 30/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.5901 - accuracy: 0.6884\n",
      "Epoch 31/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.5864 - accuracy: 0.6857\n",
      "Epoch 32/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.5871 - accuracy: 0.6909\n",
      "Epoch 33/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.5804 - accuracy: 0.6960\n",
      "Epoch 34/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.5748 - accuracy: 0.7007\n",
      "Epoch 35/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.5710 - accuracy: 0.7082\n",
      "Epoch 36/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.5696 - accuracy: 0.7073\n",
      "Epoch 37/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.5643 - accuracy: 0.7125\n",
      "Epoch 38/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.5567 - accuracy: 0.7150\n",
      "Epoch 39/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.5506 - accuracy: 0.7281\n",
      "Epoch 40/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.5429 - accuracy: 0.7337\n",
      "Epoch 41/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.5442 - accuracy: 0.7327\n",
      "Epoch 42/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.5395 - accuracy: 0.7365\n",
      "Epoch 43/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.5296 - accuracy: 0.7421\n",
      "Epoch 44/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.5275 - accuracy: 0.7475\n",
      "Epoch 45/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.5280 - accuracy: 0.7439\n",
      "Epoch 46/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.5179 - accuracy: 0.7587\n",
      "Epoch 47/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.5141 - accuracy: 0.7565\n",
      "Epoch 48/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.5061 - accuracy: 0.7627\n",
      "Epoch 49/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.5048 - accuracy: 0.7709\n",
      "Epoch 50/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.4974 - accuracy: 0.7712\n",
      "Epoch 51/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.4886 - accuracy: 0.7793\n",
      "Epoch 52/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.4953 - accuracy: 0.7712\n",
      "Epoch 53/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.4880 - accuracy: 0.7819\n",
      "Epoch 54/200\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 0.4867 - accuracy: 0.7815\n",
      "Epoch 55/200\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 0.4773 - accuracy: 0.7866\n",
      "Epoch 56/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.4844 - accuracy: 0.7873\n",
      "Epoch 57/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.4689 - accuracy: 0.7893\n",
      "Epoch 58/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.4677 - accuracy: 0.7904\n",
      "Epoch 59/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.4588 - accuracy: 0.7957\n",
      "Epoch 60/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.4509 - accuracy: 0.8050\n",
      "Epoch 61/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.4492 - accuracy: 0.8044\n",
      "Epoch 62/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.4466 - accuracy: 0.8111\n",
      "Epoch 63/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.4439 - accuracy: 0.8080\n",
      "Epoch 64/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.4444 - accuracy: 0.8088\n",
      "Epoch 65/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.4471 - accuracy: 0.8073\n",
      "Epoch 66/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.4224 - accuracy: 0.8258\n",
      "Epoch 67/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.4342 - accuracy: 0.8157\n",
      "Epoch 68/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.4129 - accuracy: 0.8312\n",
      "Epoch 69/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.4208 - accuracy: 0.8197\n",
      "Epoch 70/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.4099 - accuracy: 0.8330\n",
      "Epoch 71/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.4140 - accuracy: 0.8264\n",
      "Epoch 72/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.4186 - accuracy: 0.8266\n",
      "Epoch 73/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.4041 - accuracy: 0.8399\n",
      "Epoch 74/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.3894 - accuracy: 0.8405\n",
      "Epoch 75/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.3914 - accuracy: 0.8442\n",
      "Epoch 76/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.3840 - accuracy: 0.8441\n",
      "Epoch 77/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.3764 - accuracy: 0.8518\n",
      "Epoch 78/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.3878 - accuracy: 0.8414\n",
      "Epoch 79/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.3760 - accuracy: 0.8511\n",
      "Epoch 80/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 1s 10ms/step - loss: 0.3760 - accuracy: 0.8506\n",
      "Epoch 81/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.3542 - accuracy: 0.8654\n",
      "Epoch 82/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.3656 - accuracy: 0.8549\n",
      "Epoch 83/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.3727 - accuracy: 0.8502\n",
      "Epoch 84/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.3669 - accuracy: 0.8573\n",
      "Epoch 85/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.3491 - accuracy: 0.8694\n",
      "Epoch 86/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.3482 - accuracy: 0.8640\n",
      "Epoch 87/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.3326 - accuracy: 0.8726\n",
      "Epoch 88/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.3336 - accuracy: 0.8724\n",
      "Epoch 89/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.3224 - accuracy: 0.8798\n",
      "Epoch 90/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.3463 - accuracy: 0.8613\n",
      "Epoch 91/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.3394 - accuracy: 0.8652\n",
      "Epoch 92/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.3193 - accuracy: 0.8786\n",
      "Epoch 93/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.3247 - accuracy: 0.8743\n",
      "Epoch 94/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.3170 - accuracy: 0.8779\n",
      "Epoch 95/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.3122 - accuracy: 0.8776\n",
      "Epoch 96/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.3059 - accuracy: 0.8819\n",
      "Epoch 97/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.3094 - accuracy: 0.8784\n",
      "Epoch 98/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.3019 - accuracy: 0.8799\n",
      "Epoch 99/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.2889 - accuracy: 0.8863\n",
      "Epoch 100/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.3058 - accuracy: 0.8888\n",
      "Epoch 101/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.2925 - accuracy: 0.8875\n",
      "Epoch 102/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.2790 - accuracy: 0.8915\n",
      "Epoch 103/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.2685 - accuracy: 0.8965\n",
      "Epoch 104/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.2696 - accuracy: 0.9025\n",
      "Epoch 105/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.2876 - accuracy: 0.8862\n",
      "Epoch 106/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.2859 - accuracy: 0.8892\n",
      "Epoch 107/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.2931 - accuracy: 0.8926\n",
      "Epoch 108/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.2704 - accuracy: 0.8975\n",
      "Epoch 109/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.2507 - accuracy: 0.9053\n",
      "Epoch 110/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.2633 - accuracy: 0.9001\n",
      "Epoch 111/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.2743 - accuracy: 0.8969\n",
      "Epoch 112/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.2451 - accuracy: 0.9057\n",
      "Epoch 113/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.2644 - accuracy: 0.8975\n",
      "Epoch 114/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.2426 - accuracy: 0.9062\n",
      "Epoch 115/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.2518 - accuracy: 0.9032\n",
      "Epoch 116/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.2248 - accuracy: 0.9152\n",
      "Epoch 117/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.2593 - accuracy: 0.9014\n",
      "Epoch 118/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.2790 - accuracy: 0.8877\n",
      "Epoch 119/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.2518 - accuracy: 0.9020\n",
      "Epoch 120/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.2607 - accuracy: 0.9028\n",
      "Epoch 121/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.2624 - accuracy: 0.8964\n",
      "Epoch 122/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.2309 - accuracy: 0.9130\n",
      "Epoch 123/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.2642 - accuracy: 0.8979\n",
      "Epoch 124/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.2362 - accuracy: 0.9094\n",
      "Epoch 125/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.2627 - accuracy: 0.9032\n",
      "Epoch 126/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.2132 - accuracy: 0.9188\n",
      "Epoch 127/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.2017 - accuracy: 0.9236\n",
      "Epoch 128/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.2125 - accuracy: 0.9186\n",
      "Epoch 129/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.2167 - accuracy: 0.9183\n",
      "Epoch 130/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.2182 - accuracy: 0.9192\n",
      "Epoch 131/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.2036 - accuracy: 0.9268\n",
      "Epoch 132/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.2037 - accuracy: 0.9238\n",
      "Epoch 133/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.2087 - accuracy: 0.9255\n",
      "Epoch 134/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.2069 - accuracy: 0.9234\n",
      "Epoch 135/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.2002 - accuracy: 0.9217\n",
      "Epoch 136/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.1651 - accuracy: 0.9409\n",
      "Epoch 137/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.2038 - accuracy: 0.9217\n",
      "Epoch 138/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.1802 - accuracy: 0.9350\n",
      "Epoch 139/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.1856 - accuracy: 0.9294\n",
      "Epoch 140/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.2057 - accuracy: 0.9202\n",
      "Epoch 141/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.2203 - accuracy: 0.9171\n",
      "Epoch 142/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.1876 - accuracy: 0.9299\n",
      "Epoch 143/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.1778 - accuracy: 0.9348\n",
      "Epoch 144/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.1671 - accuracy: 0.9372\n",
      "Epoch 145/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.1832 - accuracy: 0.9360\n",
      "Epoch 146/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.1670 - accuracy: 0.9378\n",
      "Epoch 147/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.1622 - accuracy: 0.9399\n",
      "Epoch 148/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.2155 - accuracy: 0.9222\n",
      "Epoch 149/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.1661 - accuracy: 0.9391\n",
      "Epoch 150/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.2079 - accuracy: 0.9254\n",
      "Epoch 151/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.1907 - accuracy: 0.9291\n",
      "Epoch 152/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.1856 - accuracy: 0.9271\n",
      "Epoch 153/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.1775 - accuracy: 0.9365\n",
      "Epoch 154/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.1627 - accuracy: 0.9417\n",
      "Epoch 155/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.1553 - accuracy: 0.9402\n",
      "Epoch 156/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.1548 - accuracy: 0.9419\n",
      "Epoch 157/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.1597 - accuracy: 0.9403\n",
      "Epoch 158/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.1671 - accuracy: 0.9410\n",
      "Epoch 159/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 1s 10ms/step - loss: 0.1709 - accuracy: 0.9368\n",
      "Epoch 160/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.1800 - accuracy: 0.9340\n",
      "Epoch 161/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.1515 - accuracy: 0.9457\n",
      "Epoch 162/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.1750 - accuracy: 0.9331\n",
      "Epoch 163/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.1536 - accuracy: 0.9427\n",
      "Epoch 164/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.1618 - accuracy: 0.9416\n",
      "Epoch 165/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.1506 - accuracy: 0.9436\n",
      "Epoch 166/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.1533 - accuracy: 0.9448\n",
      "Epoch 167/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.1373 - accuracy: 0.9507\n",
      "Epoch 168/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.1419 - accuracy: 0.9481\n",
      "Epoch 169/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.1768 - accuracy: 0.9336\n",
      "Epoch 170/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.1389 - accuracy: 0.9501\n",
      "Epoch 171/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.1406 - accuracy: 0.9480\n",
      "Epoch 172/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.1786 - accuracy: 0.9338\n",
      "Epoch 173/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.1374 - accuracy: 0.9507\n",
      "Epoch 174/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.1306 - accuracy: 0.9530\n",
      "Epoch 175/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.1248 - accuracy: 0.9547\n",
      "Epoch 176/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.1312 - accuracy: 0.9518\n",
      "Epoch 177/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.1308 - accuracy: 0.9526\n",
      "Epoch 178/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.1143 - accuracy: 0.9595\n",
      "Epoch 179/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.1218 - accuracy: 0.9566\n",
      "Epoch 180/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.1110 - accuracy: 0.9599\n",
      "Epoch 181/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.1304 - accuracy: 0.9520\n",
      "Epoch 182/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.1317 - accuracy: 0.9503\n",
      "Epoch 183/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.1441 - accuracy: 0.9456\n",
      "Epoch 184/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.1561 - accuracy: 0.9408\n",
      "Epoch 185/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.1236 - accuracy: 0.9560\n",
      "Epoch 186/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.1281 - accuracy: 0.9546\n",
      "Epoch 187/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.1099 - accuracy: 0.9604\n",
      "Epoch 188/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.1372 - accuracy: 0.9559\n",
      "Epoch 189/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.1510 - accuracy: 0.9438\n",
      "Epoch 190/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.1165 - accuracy: 0.9571\n",
      "Epoch 191/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.1230 - accuracy: 0.9547\n",
      "Epoch 192/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.1336 - accuracy: 0.9557\n",
      "Epoch 193/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.1138 - accuracy: 0.9584\n",
      "Epoch 194/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.1041 - accuracy: 0.9626\n",
      "Epoch 195/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.1454 - accuracy: 0.9506\n",
      "Epoch 196/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.1040 - accuracy: 0.9625\n",
      "Epoch 197/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.0963 - accuracy: 0.9665\n",
      "Epoch 198/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.1232 - accuracy: 0.9601\n",
      "Epoch 199/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.1493 - accuracy: 0.9484\n",
      "Epoch 200/200\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.1172 - accuracy: 0.9567\n"
     ]
    }
   ],
   "source": [
    "training_images_number = x_train.shape[0]\n",
    "steps_per_epoch = training_images_number // BATCH_SIZE\n",
    "\n",
    "# Define the model and train\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "AqagtySHcLPg"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 23). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: trained_models/cropped_0.001/unet_inputsize256_initialfilters32_independent_patches_initialimagesnumber100_optimizerSGD_lr0.0100_epochs200/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: trained_models/cropped_0.001/unet_inputsize256_initialfilters32_independent_patches_initialimagesnumber100_optimizerSGD_lr0.0100_epochs200/assets\n"
     ]
    }
   ],
   "source": [
    "# save the model and history of the training (loss, accuracy)\n",
    "model_path = f'trained_models/cropped_0.001/unet_inputsize{INPUT_SHAPE[0]}_initialfilters{INITIAL_FILTERS}_{MODE}_initialimagesnumber{x_train.shape[0]}_optimizerSGD_lr{\"{:0.4f}\".format(model.optimizer.lr.value().numpy())}_epochs{EPOCHS}' #TODO: loss and metric'\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "N2nNTvgHsaBW"
   },
   "outputs": [],
   "source": [
    "np.save(os.path.join(model_path, 'history'), history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(model.optimizer.lr.value().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"{:0.5f}\".format(model.optimizer.lr.value().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "segm_w_on_the_fly_augm.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "deepenv",
   "language": "python",
   "name": "deepenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
