{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VAcsZ7XxW7XL",
    "outputId": "1e022db5-ec7b-44d8-c526-97133b5f7be5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import numpy as np\n",
    "from patchify import (patchify, unpatchify)\n",
    "from utils import center_crop, reconnect_patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a0lOP-N2mp6W"
   },
   "outputs": [],
   "source": [
    "# Display a list with the available models and ask the user to choose which to use\n",
    "models_path = 'models'\n",
    "models_list = os.listdir(models_path)\n",
    "\n",
    "# create a dictionary with numbers as keys and the model names as values\n",
    "models2dict = dict([(str(a), b) for a, b in enumerate(models_list)])\n",
    "\n",
    "print('List of Models', '--------------', sep='\\n')\n",
    "for item in models2dict.items():\n",
    "    print(*item, sep=' --> ')\n",
    "\n",
    "print('\\nChoose a model from the list by typing the number of its key + Enter:')\n",
    "model_name = models2dict[input()]\n",
    "print(f'\\n{model_name} was selected.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2x5kHDiEGt4k"
   },
   "outputs": [],
   "source": [
    "# Load the model\n",
    "model = keras.models.load_model(os.path.join(models_path, model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bV6_F_A-I4hc"
   },
   "outputs": [],
   "source": [
    "# Retrieve the input layer and extract the size of width of the images (which is equal to the height)\n",
    "input_layer = model.get_layer(index=0)\n",
    "input_size = input_layer.input_shape[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_fiLgoAGVqKp"
   },
   "outputs": [],
   "source": [
    "# Load the input and ground truth images \n",
    "x_initial_valid = plt.imread('validation/201-INPUT.jpg')\n",
    "y_initial_valid = plt.imread('validation/201-OUTPUT-GT.png')\n",
    "\n",
    "CROP_SIZE_W = 2560 \n",
    "CROP_SIZE_H = 2560\n",
    "\n",
    "x_initial_valid = center_crop(x_initial_valid, (CROP_SIZE_H, CROP_SIZE_W))\n",
    "y_initial_valid = center_crop(y_initial_valid, (CROP_SIZE_H, CROP_SIZE_W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SOPVSWF23qJY"
   },
   "outputs": [],
   "source": [
    "print(x_initial_valid.shape)\n",
    "print(y_initial_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rjc-22iiWKRc"
   },
   "outputs": [],
   "source": [
    "# Create patches from the input and ground truth images\n",
    "STEP = 256 \n",
    "input_patches = np.squeeze(patchify(x_initial_valid, (input_size, input_size, 3), step=STEP))\n",
    "ground_truth_patches = np.squeeze(patchify(y_initial_valid, (input_size, input_size), step=STEP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_Lrx9wAYwJdn"
   },
   "outputs": [],
   "source": [
    "predictions = np.squeeze(model.predict(np.reshape(input_patches, (-1, input_size, input_size, 3))))\n",
    "predictions = np.reshape(predictions, ground_truth_patches.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kw_g6Ayezj-b"
   },
   "outputs": [],
   "source": [
    "# TODO: To delete in the future. I can make this check in the \"reconnect_patches\" function in the utils.py\n",
    "overlapped_images = 2 * input_size / STEP\n",
    "\n",
    "assert overlapped_images == int(overlapped_images)\n",
    "overlapped_images = int(overlapped_images)\n",
    "assert overlapped_images == 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unified_shape = y_initial_valid.shape + (overlapped_images, )\n",
    "unified_predictions = reconnect_patches(predictions, unified_shape, STEP, input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2, dpi=300)\n",
    "i = 0\n",
    "for row in range(2):\n",
    "    for col in range(2):\n",
    "        ax[row, col].imshow(unified_predictions[:, :, i])\n",
    "        i += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vx6qDdoPobYT"
   },
   "outputs": [],
   "source": [
    "new_pred = unified_predictions[STEP:-STEP, STEP:-STEP]\n",
    "\n",
    "pixelwise_std = np.std(new_pred, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 190,
     "status": "ok",
     "timestamp": 1644423216316,
     "user": {
      "displayName": "Mager",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15875237439058818003"
     },
     "user_tz": -60
    },
    "id": "pylqjM1DVtfV",
    "outputId": "6c1c397f-ea2a-4f75-c0c0-af1eaa4eb92a"
   },
   "outputs": [],
   "source": [
    "np.mean(pixelwise_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 6485,
     "status": "ok",
     "timestamp": 1644424681553,
     "user": {
      "displayName": "Mager",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15875237439058818003"
     },
     "user_tz": -60
    },
    "id": "OXGt16dmwwNi",
    "outputId": "79fb2f95-d7ce-4111-8c5e-79aae82713be"
   },
   "outputs": [],
   "source": [
    "plt.figure(dpi=300)\n",
    "plt.imshow(1-pixelwise_std, cmap='Greys_r')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "net_eval.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "deepenv",
   "language": "python",
   "name": "deepenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
